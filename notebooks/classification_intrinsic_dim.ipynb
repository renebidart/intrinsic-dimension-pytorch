{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intrinsic Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from IPython.display import display\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from utils.train_val import train_net #, train_epoch, validate_epoch, save_checkpoint\n",
    "from utils.data_loaders import mnist_loaders\n",
    "\n",
    "# sys.path.append(str(Path.cwd().parent.parent))\n",
    "# from pytorch_testing.tests.unit_tests import Tester, SimpleNet\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "DEVICE = torch.device(\"cuda:1\")\n",
    "PATH = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallFCNetMNIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SmallFCNetMNIST, self).__init__()\n",
    "        self.layers = torch.nn.ModuleDict()\n",
    "        self.layers['fc1'] = nn.Linear(28*28, 128)\n",
    "        self.layers['fc2'] = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.layers['fc1'](x))\n",
    "        x = self.layers['fc2'](x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SmallFCNetMNIST' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7f2f9e53749d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist_loaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSmallFCNetMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SmallFCNetMNIST Acc with all params:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'best_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SmallFCNetMNIST' is not defined"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = mnist_loaders(PATH, bs=256)\n",
    "model = SmallFCNetMNIST().to(DEVICE)\n",
    "metrics = train_net(model, train_loader, val_loader, epochs=30, verbose=0, device=DEVICE)\n",
    "print('SmallFCNetMNIST Acc with all params:', metrics['val']['best_acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense matrix projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseProjSmallFCNetMNIST(nn.Module):        \n",
    "    def __init__(self, d, DEVICE='cuda'):\n",
    "        super(DenseProjSmallFCNetMNIST, self).__init__()\n",
    "        self.layers = torch.nn.ModuleDict()\n",
    "        self.layers['fc1'] = nn.Linear(28*28, 128)\n",
    "        self.layers['fc2'] = nn.Linear(128, 10)\n",
    "        self.d = d\n",
    "#         self.opt_basis= torch.zeros(self.d).to(DEVICE)\n",
    "        self.opt_basis = nn.Parameter(torch.zeros(self.d).to(DEVICE), requires_grad=True)\n",
    "\n",
    "        self.get_projection_matrix()\n",
    "            \n",
    "    def get_projection_matrix(self):\n",
    "        self.D = 0\n",
    "        for name, layer in self.layers.items():\n",
    "            self.D += torch.prod(torch.tensor(layer.weight.size()))\n",
    "            if layer.bias is not None:\n",
    "                self.D += torch.prod(torch.tensor(layer.bias.size()))\n",
    "            layer.requires_grad = False # none of the layers will be updated\n",
    "        \n",
    "        proj_matrix = nn.Parameter(torch.randn(self.D, self.d).to(DEVICE), requires_grad=False)\n",
    "        proj_matrix = F.normalize(proj_matrix, dim=1, p=2)\n",
    "        \n",
    "        # Turn it into a nice format for a weight and bias matrix for each layer\n",
    "        param_idx = 0\n",
    "        self.projection = {}\n",
    "        for name, layer in self.layers.items():\n",
    "            self.projection[name] = {}\n",
    "            n_weight_params = torch.prod(torch.tensor(layer.weight.size()))\n",
    "            self.projection[name]['weight'] = proj_matrix[param_idx : param_idx + n_weight_params, :]\n",
    "            self.projection[name]['weight'].requires_grad = False\n",
    "            # also make sure the layers aren't trainable\n",
    "            self.layers[name].weight.requires_grad = False\n",
    "            param_idx += n_weight_params\n",
    "            if layer.bias is not None:\n",
    "                n_bias_params = torch.prod(torch.tensor(layer.bias.size()))\n",
    "                self.projection[name]['bias'] = proj_matrix[param_idx : param_idx + n_bias_params, :]\n",
    "                self.projection[name]['bias'].requires_grad = False\n",
    "                # also make sure the layers aren't trainable\n",
    "                self.layers[name].bias.requires_grad = False\n",
    "                param_idx += n_bias_params\n",
    "#         print(f'Model contains {self.D} params, but only optimizing a {self.d} dim subspace')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        new_weight = self.layers['fc1'].weight + torch.matmul(self.projection['fc1']['weight'], self.opt_basis\n",
    "                                                   ).view(self.layers['fc1'].weight.size())\n",
    "        new_bias = self.layers['fc1'].bias + torch.matmul(self.projection['fc1']['bias'], self.opt_basis\n",
    "                                                   ).view(self.layers['fc1'].bias.size())\n",
    "        x = F.linear(input = x, \n",
    "                     weight=new_weight, \n",
    "                     bias=new_bias\n",
    "                    )\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        new_weight = self.layers['fc2'].weight + torch.matmul(self.projection['fc2']['weight'], self.opt_basis\n",
    "                                                   ).view(self.layers['fc2'].weight.size())\n",
    "        new_bias = self.layers['fc2'].bias + torch.matmul(self.projection['fc2']['bias'], self.opt_basis\n",
    "                                                   ).view(self.layers['fc2'].bias.size())\n",
    "        x = F.linear(input = x,\n",
    "                     weight=new_weight, \n",
    "                     bias=new_bias\n",
    "                    )\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseProjSmallFCNetMNIST Acc with 1024 params: 0.9258\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = mnist_loaders(PATH, bs=256)\n",
    "model = DenseProjSmallFCNetMNIST(d=1024, DEVICE=DEVICE).to(DEVICE)\n",
    "metrics = train_net(model, train_loader, val_loader, epochs=30, verbose=0, device=DEVICE)\n",
    "print(f'DenseProjSmallFCNetMNIST Acc with 1024 params: {metrics[\"val\"][\"best_acc\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseProjSmallFCNetMNIST Acc with 8 params: 0.1602\n",
      "DenseProjSmallFCNetMNIST Acc with 16 params: 0.2389\n",
      "DenseProjSmallFCNetMNIST Acc with 32 params: 0.3351\n",
      "DenseProjSmallFCNetMNIST Acc with 64 params: 0.5496\n",
      "DenseProjSmallFCNetMNIST Acc with 128 params: 0.6981\n",
      "DenseProjSmallFCNetMNIST Acc with 256 params: 0.8053\n",
      "DenseProjSmallFCNetMNIST Acc with 512 params: 0.8829\n",
      "DenseProjSmallFCNetMNIST Acc with 1024 params: 0.9248\n",
      "DenseProjSmallFCNetMNIST Acc with 2056 params: 0.9486\n"
     ]
    }
   ],
   "source": [
    "d_list = [8, 16, 32, 64, 128, 256, 512, 1024, 2056]\n",
    "results = []\n",
    "for d in d_list:\n",
    "    train_loader, val_loader = mnist_loaders(PATH, bs=256)\n",
    "    model = DenseProjSmallFCNetMNIST(d=d, DEVICE=DEVICE).to(DEVICE)\n",
    "    metrics = train_net(model, train_loader, val_loader, epochs=30, verbose=0, device=DEVICE)\n",
    "    print(f'DenseProjSmallFCNetMNIST Acc with {d} params: {metrics[\"val\"][\"best_acc\"]}')\n",
    "    results.append(metrics[\"val\"][\"best_acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAENCAYAAADjd3fVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XmYXGWd9vHv3Z1esi+kgaSTkAABiWxCG2FwHBRUwDFxQZZXUdxw5hV3HWH0ZRBmXBhHxxmZGVGD6AgJqGjEKKjoOC6QBAloEoEYoNNpknSWztrp9ff+cU6HolKdVEh3bX1/ritXVZ3zVNWv66T7ruc5zzlHEYGZmZlVlqpiF2BmZmaDzwFvZmZWgRzwZmZmFcgBb2ZmVoEc8GZmZhXIAW9mZlaBHPBmZmYVyAFvZmZWgRzwZmZmFWhEsQs4HJMnT46ZM2cWuwwzM7OCeOihhzZHREM+bcs64GfOnMny5cuLXYaZmVlBSHo637YeojczM6tADngzM7MK5IA3MzOrQA54MzOzCuSANzMzq0AOeDMzswrkgDczM6tAZX0cvJmZ2VCICLp7g86ePvb29Ka3fcltd/K4s/fZ+/vW9bftTtZXS/z9+bOL8jM44M3MrGREJKH6bGj2ZgRr1uM0THOF70CBm71+wADv7SPi8H+eiSNrHPBmZlY8vX1B5wBBlwTrwXqyBw7LgdZnB3hXb9+g/Dw11aJuRBX1I6rT26rktqaauuoq6muqGFNXs2/9s22qM9pWUVddndwOtD7jca73G1FdvD3hDngzsyKJCHr6Yv+e5CGG5YA91uf0dg/cG+7pG4TuKmSFZUbg1VRRV13FyJpqJoys2S8s92t7kHDOtT6zTVWVBuXnKWcOeDMbdiKCrt6+54TpQfen5grcrPWdvb2HHM6DkasS+/cu+x+nYTi2rprJo2v3C97M8K2vqT5gOA+0vr9NbXUVkoO1VDjgzaxg+vqCzt7nDu8OvD81Myxz9D57919/KPteB0N1lQ4ahhNH1uRcv6+3mStQRxxk/b7XSAJ8RJUcrLYfB7yZ5dTd28eGHZ2s37GX1u17Wb99L8/s3Mvurt48wjl3gHf3Ds4wcE21DhqGY+vqDrj+0IeAn+0N9wd0Mfevmh2MA95smIkItuzuek5wt+7oZP32jufcbtrVud8s4uoqMaa2esAwHFlTnbvHmj2ce5DJSgcaGq71/lWzvDjgzSrI7s4eWnf0h3bW7fa9aah35pypPHl0LY3j65k6rp4zp01g6rj65PH4ehrHJbcNo2sdrmZlwgFvVga6e/vYuLPzIMG9l+17e/Z77uja6n3Bfc7MSTmDe8q4OupGVBfhJzOzoVKwgJd0AfAloBr4WkR8Nmv9McACoAHYCrwlIloKVZ9ZMUQEW/d0HzS4N+YYLh9RJaaMq2PquHpOOnIM5x0/eb/gbhxfz9i6EZ6AZTYMFSTgJVUDNwOvBFqAZZIWR8SqjGafB74ZEbdJegXwGeCKQtRnNhT2dPVkBXYn63d0JLfpfu7WHXtzzuiePLp2X0/7RVPHp8FdR+P4kUwdl9x6uNzMDqRQPfi5wJqIWAsgaSEwH8gM+DnAh9L7vwC+X6DazA5JT28fG3Z25uxpZwZ6ruHyUbXVNKbBffYxE5/tcadD6I0eLjezQVKogG8E1mU8bgFektXmEeCNJMP4rwfGSjoiIrZkNpJ0FXAVwIwZM4asYBt++ofLDxbcuYbLq6vElLF1NI6v58Qjx/CK4yfvF9xTx9Uzrt7D5WZWGIUK+Fx/0bIPiP0o8GVJVwK/AtYD+3WBIuIW4BaApqamwTmo1irenq6eZw8B2z7AZLUBhsuPGFWzL6xPmzpuv9BuHF9Pw5g6qj1cbmYlpFAB3wJMz3g8DWjNbBARrcAbACSNAd4YEdsLVJ+VqZ7ePjbu6nzOfu312zuygruT9o7u/Z47sqaKxvEjaRxfz1n9w+Xjnrufe8q4OuprPFxuZuWnUAG/DJgtaRZJz/wy4P9kNpA0GdgaEX3AtSQz6m0Y27ani/XbBzimu3+4fGfnfufyrq4SR6fD5Sc0jOHlx0/er8c9dXw94z1cbmYVrCABHxE9kq4G7iU5TG5BRKyUdAOwPCIWA+cCn5EUJEP07y1EbVZatuzu4vbfr2fB0mZWtO7Yb/2kUTX7gvrUKeNyBveRHi43M0MxGFe0L5KmpqZYvnx5scuww9TbF/z8iTYWLF3H3X/YQFdvH2dMG8+bTp3CrEmj9gX31HH1Hi43s2FN0kMR0ZRPW5/Jzopm7ZbdfGPZOr6xbB3r2vcyaVQNf/MXx/D2F0/n9MbxxS7PzKysOeCtoDq6e/neo8+wYOk67l+zGQledUIDn3/tC5l/8lE+/tvMbJA44G3IRQTL121nwdJm7nh4Pdv39jBr0ihuvOBE3tY0nekTRxa7RDOziuOAtyHTtquTb6cT5v7wzE7qR1Rx8WlTeOfcGbzs2CN8mlUzsyHkgLdB1dPbx32PJxPmFq/cQHdvMHfGBP7r4lO47PRGxo+sKXaJZmbDggPeBsWazbu5dWkz31jWQuuOvUweXcvV58ziHXOnc/KUccUuz8xs2HHA2/O2u7OH7zz6DAuWNvOrtVupElz4giP599efzF/POYraEVXFLtHMbNhywNshiQgebG7n6w82s2hFKzs7ezh+8mg+fdELeGvTNBrHe8KcmVkpcMBbXjbu7ORby1tYsKyZ1Rt3Maq2mktOm8o75k7npbMm+ZSvZmYlxgFvA+rp7ePHf9rE1x9s5kerN9HTF5x9zES++qZTufT0RsbW+7+PmVmp8l9o28+fNu7k1mXr+ObyFjbs7OTIMbV86GXH8va50znpqLHFLs/MzPLggDcAdu7t4a5HWvn60mZ++9Q2qqvEa046knfMncFFJx1JTbUnzJmZlRMH/DAWEfzmya0sWLqOOx9pZXdXLyc2jOamvz6JK86cxtHj6otdopmZPU8O+GHomR17+ebyFhYsbebxtt2MqavmstMbecfc6Zw9c6InzJmZVQAH/DDR1dPHj1ZvZMHSdfz4T5vo7Qv+8thJXPuK2Vx82hTG1Pm/gplZJfFf9Qq3csNObl3azDcfaqFtVxdTxtXxsXOP4+1zp3NCw5hil2dmZkOkYAEv6QLgS0A18LWI+GzW+hnAbcCEtM01EbGkUPVVku0d3Sxa0cqCpc082NzOiCox74VH8Y65M3j1iQ2M8IQ5M7OKV5CAl1QN3Ay8EmgBlklaHBGrMpp9ErgzIv5T0hxgCTCzEPVVii27u/joD1exaMV6Orr7mHPUGP5l3hzecsY0jhxbV+zyzMysgArVg58LrImItQCSFgLzgcyAD6D/qiTjgdYC1VYRdu7t4cKvPsgjrTt4+9zpvGPudF48fYInzJmZDVOFCvhGYF3G4xbgJVltrgfuk/Q+YDRwfmFKK38d3b28dsFSfr9+O999WxPzTz662CWZmVmRFWpnbK5uZGQ9vhz4RkRMAy4CviVpv/okXSVpuaTlbW1tQ1Bqeenq6ePi25bzq7VbuO2y0x3uZmYGFC7gW4DpGY+nsf8Q/DuBOwEi4ndAPTA5+4Ui4paIaIqIpoaGhiEqtzz09gVX3P4wS1Zv4j/feApvPnNasUsyM7MSUaiAXwbMljRLUi1wGbA4q00zcB6ApJNIAt5d9AFEBO+561HufKSVm/76JN5z9sxil2RmZiWkIAEfET3A1cC9wGqS2fIrJd0gaV7a7CPAuyU9AtwBXBkR2cP4RhLuH168kq8vbeaT58/mYy8/vtglmZlZiSnYcfDpMe1LspZdl3F/FXBOoeopZ5+673H+9VdP8v6/nMUNF5xY7HLMzKwE+YwnZeYL//NnPnXf41z54ul8cd4LfRicmZnl5IAvI1994Gk+sngVF586ha++6VSqqhzuZmaWmwO+TCx8eD3v+c6jXPCCBr795jN8ulkzMzsgp0QZuGfVRq64/WFeOmsS331bE7UjvNnMzOzAnBQl7hdrNnPxbcs5vXEc97xzLqNqfQFAMzM7OAd8CXvw6W3MW7CU444YxU/efRbj6muKXZKZmZUJB3yJerR1Bxd+9UGOHFPHT99zNkeMri12SWZmVkYc8CXoibZdvOqWBxhVW83P3nM2U8fXF7skMzMrM96hW2Kat+3h/K88QG9f8Iu/PZtZR4wqdklmZlaG3IMvIRt3dnL+fz3A9o5u7rvqLE46amyxSzIzszLlHnyJ2Lani1d95QHW79jLfVedxYumjS92SWZmVsbcgy8Buzp7uOhrS/nTpl18/8oXc86sScUuyczMypx78EW2t7uX+QuWsWxdO3e99UxeeeLwvsa9mZkNDvfgi6i7t49LvvkQ96/ZzK2XnsbrT5lS7JLMzKxCOOCLpLcvuPKOFfxw1UZufsMpXNE0vdglmZlZBXHAF0FE8H+/+yi3P7yez1z0Av7vOTOLXZKZmVWYggW8pAskPSZpjaRrcqz/oqQV6b/HJbUXqrZCigj+7p7V3PJAM9eedzzXnDe72CWZmVkFKsgkO0nVwM3AK4EWYJmkxRGxqr9NRHwoo/37gBcVorZC+6efPcHnf/ln3nvOTP7pwhcUuxwzM6tQherBzwXWRMTaiOgCFgLzD9D+cuCOglRWQF/61Vr+308e461N0/i3152MpGKXZGZmFapQAd8IrMt43JIu24+kY4BZwP0FqKtg7lzRygd/sJLXn3I0X7/kNKqqHO5mZjZ0ChXwudIsBmh7GfCdiOjN+ULSVZKWS1re1tY2aAUOtc/e/wSnThnHHW85gxHVnttoZmZDq1BJ0wJkHgc2DWgdoO1lHGB4PiJuiYimiGhqaCiPk8I83raLh9fv4MoXT6NuRHWxyzEzs2GgUAG/DJgtaZakWpIQX5zdSNKJwETgdwWqqyAWrUi+y7zptKlFrsTMzIaLggR8RPQAVwP3AquBOyNipaQbJM3LaHo5sDAiBhq+L0uLVrTy0lmTmDZhZLFLMTOzYaJg56KPiCXAkqxl12U9vr5Q9RTKyg07WblhJ19+/cnFLsXMzIYRz/YaYotWrKdKcLGH583MrIAc8EMoIli0opVzj5vMUWPril2OmZkNIw74IfRI6w4eb9vNpae7925mZoXlgB9CCx9upbpKvOGUo4tdipmZDTMO+CESESx6ZD3nz57M5DEenjczs8JywA+RZevaeWprB5ednvOMvGZmZkMqr4CX9H5Jk4e6mEqyaEUrtdVVvM7D82ZmVgT59uDPB56SdI+kSyV5zPkA+vqCO1e08uoTG5gwsqbY5ZiZ2TCUV8BHxDzgGODHwAeBDZK+JullQ1lcufrd09to2b7Xs+fNzKxo8t4HHxFbIuLmiDgb+CvgxcAvJD0l6ROSxgxZlWVm4cPrqR9RxbwXenjezMyK45Am2Uk6T9KtwC+BjcBbgSuAF5H07oe93r7gO48+w2vmHMXY+oKdCdjMzOw58kogSZ8nuQLcduCbwCcjYn3G+geAbUNSYZn51dotbNjZ6eF5MzMrqny7mPXA6yNiWa6VEdEtqWnwyipfi1a0Mrq2mtecdGSxSzEzs2Es34D/DLAnc4GkicDIiGgFiIg/DXJtZae7t4/vPvoMr51zFKNqPTxvZmbFk+8++O8D07KWTQPuHtxyytv9T2xm8+4uD8+bmVnR5RvwJ0bEHzIXpI9fMPglla9FK1oZVz+CC17g4XkzMyuufAN+k6TjMxekj7fk+0aSLpD0mKQ1kq4ZoM0lklZJWinp9nxfuxR09fRx9x838LqTj6a+prrY5ZiZ2TCX747iBcB3JX0CWAscB9wIfC2fJ0uqBm4GXgm0AMskLY6IVRltZgPXAudExDZJZdUNvu/xNto7uj08b2ZmJSHfgP8s0A18HpgOrCMJ9y/k+fy5wJqIWAsgaSEwH1iV0ebdwM0RsQ0gIjbl+dolYdGK9UwcWcP5sxuKXYqZmVl+AR8RfcA/p/+ej0aSLwX9WoCXZLU5AUDSb4Bq4PqI+MnzfL+C6uju5Qd/3Mglp02ldoQv0GdmZsWX97FckmqBE4HJgPqXR8T9+Tw9x7LIUcts4FySGfr/K+nkiGjPquMq4CqAGTNm5Fv+kPrx6k3s7Ozx8LyZmZWMfM9k91LgLqAOGAfsAMaS9MqPzeMlWkiG9vtNA1pztHkgIrqBJyU9RhL4zzm5TkTcAtwC0NTUlP0loSgWrWilYUwtLz/+iGKXYmZmBuQ/i/6LwE0RMQnYmd7eCPxHns9fBsyWNCsdCbgMWJzV5vvAywHSa8+fQDKhr6Tt7uzhntUbufjUKYyo9vC8mZmVhnwT6QTgS1nLPgt8KJ8nR0QPcDVwL7AauDMiVkq6QdK8tNm9wBZJq4BfAB+LiLwPwyuWe1ZtZE9Xr4fnzcyspOS7D347ydB8O/CMpDkkx8DnfYnYiFgCLMladl3G/QA+nP4rG4seaWXKuDpeOsvD82ZmVjry7cF/D7govf91kh72QyT75YetHXu7WbJ6E286bSrVVbnmEZqZmRVHvofJfTDj/r9IepBkkt29Q1VYOfjBHzfQ2dPHpad5eN7MzErLQQM+PQvd48CciOgEiIhfD3Vh5WDRilZmTBzJWcdMLHYpZmZmz3HQIfqI6AV6Sa4Jb6lte7q47/E2LjltKlUenjczsxKT7yS7fwXulPRpkuPV9x1/3n/62eHm7j9soLs3PHvezMxKUr4B/+X09pVZy4PktLLDzqIVrRx7xCjOnDa+2KWYmZntJ69Z9BFRNcC/YRnubbs6+fmazVx6+lQkD8+bmVnp8anXnodfP7mV3r5g3guPLnYpZmZmOeV7Lvr/Zf+LwwAQES8b1IrKwNPbOgCYPXl0kSsxMzPLLd998F/Lenw08E7gvwe3nPLQvK2DUbXVTBpVU+xSzMzMcsr3RDe3ZS+T9F3gVuCGwS6q1DW3dzBjwkjvfzczs5J1OPvg1wOnDlYh5eTpbXs4ZuLIYpdhZmY2oHz3wb8ja9Eo4A3AA4NeURlo3tbBixp9eJyZmZWufPfBX5H1eDfwW5LrxA8rHd29bNrVxYwJ7sGbmVnpyncf/MuHupBy0dKezKCf4SF6MzMrYXntg5f0VkmnZi07TVJ2z77iNaeHyLkHb2ZmpSzfSXY3Auuylq0D/jHfN5J0gaTHJK2RdE2O9VdKapO0Iv33rnxfu5Ca0x78MRNHFbkSMzOzgeW7D34csCNr2XZgQj5PTi85ezPJuexbgGWSFkfEqqymiyLi6jxrKoqnt3UgQeN4X1zPzMxKV749+FXAG7OWvR5Ynefz5wJrImJtRHQBC4H5eT63pDRv62DK2HpqR/gsv2ZmVrry7cF/HFgi6VLgz8DxwHnARXk+v5HnDvG3AC/J0e6Nkl4GPA58KCKydwsUXXN7hyfYmZlZycv3anK/Bl4ILANGA0uBkyPiN3m+T65TvmWf2/6HwMyIOBX4GbDf2fMAJF0labmk5W1tbXm+/eBp3tbhCXZmZlby8j3RTR2wISI+m7GsRlJdRHTm8RItwPSMx9OA1swGEbEl4+FXgc/leqGIuAW4BaCpqSnnBXCGSkTQ3N7B/JN9FTkzMytt+e5I/ilwZtayM4F783z+MmC2pFmSaoHLgMWZDSRNyXg4j/z37xdM264uOnv6fJpaMzMrefnugz8FeDBr2VLgtHyeHBE9kq4m+UJQDSyIiJWSbgCWR8Ri4P2S5gE9wFbgyjxrK5infQy8mZmViXwDfjtwFLAhY9lRJKeszUtELAGWZC27LuP+tcC1+b5eMTS37wF8FjszMyt9+Q7Rfxe4XdLJkkZJOgX4FnDX0JVWevadxc4Bb2ZmJS7fgP8EyT7xpcAukqvIrQY+OUR1laTm9g5G11YzcWRNsUsxMzM7oHwPk9sbEe8lOUTuKOBsoBN4YghrKznN2zo4ZuJIpFxH/ZmZmZWOvE/HJqkBeD/JRLmHgSbgA0NUV0l6eptPcmNmZuXhgJPsJNWQHLJ2JfBqYA1wBzATuCQiNg1xfSWlub2DM6eNL3YZZmZmB3WwHvxG4CvAY8BZETEnIm4kGZ4fVjq6e2nb1eUevJmZlYWDBfyjJFeMewnwYkkTh76k0rSu3cfAm5lZ+ThgwEfEucBxwH3AR4ENkn5IMtluWE0l9yFyZmZWTg46yS4ino6IGyNiNskV5J4B+oBHJN001AWWiv6AP2biqCJXYmZmdnCHdFHziPh1RFwFHA28j+QUtsPC09s6kKBxfH2xSzEzMzuoQwr4fulx8XdExIWDXVCpam7vYOq4emqqn9dHZmZmVlBOqzz5OvBmZlZOHPB5am73SW7MzKx8OODz0NcXrGvv8HXgzcysbDjg87BpVyedPX0eojczs7LhgM9Dc7uPgTczs/JSsICXdIGkxyStkXTNAdpdLCkkNRWqtoPxSW7MzKzcFCTgJVUDNwMXAnOAyyXNydFuLMkV6x4sRF35avZpas3MrMwUqgc/F1gTEWsjogtYCMzP0e5G4CZgb4Hqykvztg7G1o1gwshhdXZeMzMrY4UK+EZgXcbjlnTZPpJeBEyPiHsKVFPe+g+Rk1TsUszMzPJSqIDPlYyxb6VUBXwR+MhBX0i6StJyScvb2toGscSBPe2T3JiZWZkpVMC3ANMzHk8DWjMejwVOBn4p6SngLGBxrol2EXFLRDRFRFNDQ8MQlvys5m0+yY2ZmZWXQgX8MmC2pFmSaoHLgMX9KyNie0RMjoiZETETeACYFxHLC1TfgPZ09bB5d5d78GZmVlYKEvAR0QNcDdwLrAbujIiVkm6QNK8QNTxf69qT+X7uwZuZWTkZUag3ioglwJKsZdcN0PbcQtSUj2evA++ANzOz8uEz2R3E09v2AD4G3szMyosD/iCa2zuoEkwdX1/sUszMzPLmgD+I5m0dTB1XT021PyozMysfTq2D8HXgzcysHDngD6J5WwfHTBxV7DLMzMwOiQP+APr6gnXtez3BzszMyo4D/gA27uqkq7fPQ/RmZlZ2HPAH4OvAm5lZuXLAH4CvA29mZuXKAX8A7sGbmVm5csAfQHN7B+PqRzBhZE2xSzEzMzskDvgDeGrrHg/Pm5lZWXLAH8DaLXs47ggfA29mZuXHAT+AiGDt1j3McsCbmVkZcsAPoG1XF3u6ejl20uhil2JmZnbIHPADWLs1uUzsse7Bm5lZGSpYwEu6QNJjktZIuibH+r+R9AdJKyT9WtKcQtWWy9otuwGYNckBb2Zm5acgAS+pGrgZuBCYA1yeI8Bvj4hTIuJ04CbgC4WobSBrtyQ9+JmTPIvezMzKT6F68HOBNRGxNiK6gIXA/MwGEbEj4+FoIApUW05Pbt3DlHF1jKodUcwyzMzMnpdCpVcjsC7jcQvwkuxGkt4LfBioBV5RmNJyW7tlj4fnzcysbBWqB68cy/broUfEzRFxHPBx4JM5X0i6StJyScvb2toGucxnrd26xxPszMysbBUq4FuA6RmPpwGtB2i/EHhdrhURcUtENEVEU0NDwyCW+Kyunj5a2jt8iJyZmZWtQgX8MmC2pFmSaoHLgMWZDSTNznj4GuCJAtW2n+b2DvrCM+jNzKx8FWQffET0SLoauBeoBhZExEpJNwDLI2IxcLWk84FuYBvwtkLUlkv/IXIeojczs3JVsCniEbEEWJK17LqM+x8oVC0H86RPcmNmZmXOZ7LLYe2WPdRWVzF1XH2xSzEzM3teHPA5rN2yh5mTRlJVlWvyv5mZWelzwOfwpA+RMzOzMueAz2Htlj0+RM7MzMqaAz7Ltj1dbOvo9iFyZmZW1hzwWTyD3szMKoEDPosD3szMKoEDPkv/ZWI9RG9mZuXMAZ9l7ZY9TBpVw/iRNcUuxczM7HlzwGfxIXJmZlYJHPBZ1rV3MH3CyGKXYWZmdlgc8Fk27+7iyDF1xS7DzMzssDjgM/T1BVv2dDN5dG2xSzEzMzssDvgM7Xu76e0LGhzwZmZW5hzwGdp2dQG4B29mZmXPAZ+hbVcnAA1jHPBmZlbeChbwki6Q9JikNZKuybH+w5JWSXpU0s8lHVOo2vpt3u0evJmZVYaCBLykauBm4EJgDnC5pDlZzR4GmiLiVOA7wE2FqC1TWxrwDaM9i97MzMpboXrwc4E1EbE2IrqAhcD8zAYR8YuI2JM+fACYVqDa9tnXg/cQvZmZlblCBXwjsC7jcUu6bCDvBH48pBXl0Lari9G11YysqS70W5uZmQ2qEQV6H+VYFjkbSm8BmoC/GmD9VcBVADNmzBis+oCkB+/972ZmVgkK1YNvAaZnPJ4GtGY3knQ+8AlgXkR05nqhiLglIpoioqmhoWFQi2zb3ekZ9GZmVhEKFfDLgNmSZkmqBS4DFmc2kPQi4Csk4b6pQHU9h3vwZmZWKQoS8BHRA1wN3AusBu6MiJWSbpA0L232z8AY4C5JKyQtHuDlhkzbri7PoDczs4pQqH3wRMQSYEnWsusy7p9fqFoGsnl3l4fozcysIvhMdqmO7l52d/V6iN7MzCqCAz61eVf/SW4c8GZmVv4c8Km23cmkfffgzcysEjjgU/1XkmsY40l2ZmZW/hzwKV9oxszMKokDPnX02DrecMrRHDXWPXgzMyt/BTtMrtSdd0ID550wuGfGMzMzKxb34M3MzCqQA97MzKwCOeDNzMwqkAPezMysAjngzczMKpAD3szMrAI54M3MzCqQA97MzKwCKSKKXcPzJqkNeHqQXm4ysHmQXssOj7dF6fC2KB3eFqWjmNvimIjI66xsZR3wg0nS8ohoKnYd5m1RSrwtSoe3Rekol23hIXozM7MK5IA3MzOrQA74Z91S7AJsH2+L0uFtUTq8LUpHWWwL74M3MzOrQO7Bm5mZVaBhH/CSLpD0mKQ1kq4pdj3DgaSnJP1B0gpJy9NlkyT9VNIT6e3EdLkk/Vu6fR6VdEZxqy9vkhZI2iTpjxnLDvmzl/S2tP0Tkt5WjJ+lEgywPa6XtD79/Vgh6aKMddem2+MxSa/OWO6/Y4dB0nRJv5C0WtJKSR9Il5f370ZEDNt/QDXwZ+BYoBZ4BJhT7Loq/R/wFDA5a9lNwDXp/WuAz6X3LwJ+DAg4C3iw2PWX8z/gZcAZwB+f72cPTALWprcT0/sTi/2zleO/AbbH9cBHc7Sdk/6NqgNmpX8+fUmbAAAIR0lEQVS7qv13bFC2wxTgjPT+WODx9PMu69+N4d6DnwusiYi1EdEFLATmF7mm4Wo+cFt6/zbgdRnLvxmJB4AJkqYUo8BKEBG/ArZmLT7Uz/7VwE8jYmtEbAN+Clww9NVXngG2x0DmAwsjojMingTWkPwN89+xwxQRz0TE79P7O4HVQCNl/rsx3AO+EViX8bglXWZDK4D7JD0k6ap02VER8Qwkv2zAkelyb6Ohd6ifvbfJ0Ls6Hfpd0D8sjLdHQUiaCbwIeJAy/90Y7gGvHMt8WMHQOycizgAuBN4r6WUHaOttVDwDffbeJkPrP4HjgNOBZ4B/SZd7ewwxSWOA7wIfjIgdB2qaY1nJbYvhHvAtwPSMx9OA1iLVMmxERGt6uwm4m2SIcWP/0Ht6uylt7m009A71s/c2GUIRsTEieiOiD/gqye8HeHsMKUk1JOH+7Yj4Xrq4rH83hnvALwNmS5olqRa4DFhc5JoqmqTRksb23wdeBfyR5HPvn3H6NuAH6f3FwFvTWatnAdv7h8xs0BzqZ38v8CpJE9Ph41ely2wQZM0xeT3J7wck2+MySXWSZgGzgaX479hhkyTg68DqiPhCxqqy/t0YUaw3LgUR0SPpapINUA0siIiVRS6r0h0F3J38PjECuD0ifiJpGXCnpHcCzcCb0vZLSGasrgH2AG8vfMmVQ9IdwLnAZEktwD8An+UQPvuI2CrpRpJgAbghIvKdKGYZBtge50o6nWRo9yngPQARsVLSncAqoAd4b0T0pq/jv2OH5xzgCuAPklaky/6eMv/d8JnszMzMKtBwH6I3MzOrSA54MzOzCuSANzMzq0AOeDMzswrkgDczM6tADnizApI0Q9IuSdXP8/m7JB1bSjUNwvv/uOhX3cog6S8lPVbsOswOlw+TMzsASVcCHyE5degOkjPvXRsR7Xk+/yngXRHxs6Gq8VAVsiZJQXKccACdwArglohYNNTvbTbcuQdvNgBJHwE+B3wMGE9yWchjgJ+mZwyz/JwWEWOAE4FvAF+W9A/FLcms8jngzXKQNA74FPC+iPhJRHRHxFPAJSQh/5a03fWSviNpkaSdkn4v6bR03beAGcAP0yHwv5M0U1JIGpG2+aWkf5T027TNDyUdIenbknZIWpZe3aq/rpB0vKSpafv+f3vS3jKSjpN0v6QtkjanrzXhEGqaKmmxpK2S1kh6d8b7Xy/pTknfTH/elZKa8vlMI2JzRHwL+FvgWklHZHwG70rvXynpN5K+KKld0lpJf5EuXydpU+Zwfnra1s9Lapa0UdJ/SRqZrjtXUoukj6TPe0bS2zOee5GkVenPsV7SRzOfl9HupLTG9vTnnZex7huSbpb0o/R1HpR0XD6fh9lQc8Cb5fYXQD3wvcyFEbEL+DHwyozF84G7gEnA7cD3JdVExBUkp7d8bUSMiYibBnivy0hOk9lIsivgd8Ct6eutJjl96XNERGv6mmPS3vHdJNcBh+SKVp8BpgInkVz84vr0efnUdAfJRTOmAhcDn5Z0Xsb6eel7TSA5J/eXB/i5BvIDktMUzx1g/UuAR4EjSD7PhcCLgeNJvlh9WclVvyAZYTmB5Mprx5N8htdlvNbRJKMvjcA7gZv17OVXvw68JyLGAicD92cXouQCJD8E7iO5VOj7gG9LOjGj2eUkXwYnkpy69J/y+RDMhpoD3iy3ycDmiOjJse6ZdH2/hyLiOxHRDXyB5IvBWYfwXrdGxJ8jYjvJl4c/R8TP0ve+i+Ta1AOS9HHgBcA7ACJiTUT8NCI6I6Itremv8ilE0nTgpcDHI2JvRKwAvkbyBaTfryNiSXoe9G8Bpx3Cz0r6OW0m+QKTy5MRcWv6+otIvqDckP489wFdwPGSBLwb+FBEbI2IncCnSb4w9etOn9sdEUuAXSS7CvrXzZE0LiK2RcTvc9RyFjAG+GxEdEXE/cA9JKHe73sRsTTdXt8m+bJhVnQOeLPcNpNcACTXBZmmpOv7reu/k17is7/3m6+NGfc7cjwewwAkXQh8AHhdRHSky46UtDAddt4B/DfP/UJyIFOB/rDs9zRJD7jfhoz7e4D6AT6ngWquARqAgS7Ckf3zExG5PpMGYBTwUDp83g78JF3eb0vWl7Q9PPt5vpHkgiFPS/ofSWfnqGUqsC7drv0O9nkMuL3MCskBb5bb70hmfb8hc6GSS9xeCPw8Y/H0jPVVPPca0EN2mEo6THwbcElErMtY9Zn0fU+NiHEkw9rKWH+gmlqBSUov6ZuaAawfnKqBZJdGD8mlTg/HZpKwf2FETEj/jU93WRxURCyLiPkkQ+/fB+7M0awVmJ5u136D/XmYDQkHvFkO6XD5p4B/l3SBpJp0sttdJD30b2U0P1PSG9Je7AdJvhg8kK7bCAzqceuwbxLgD4BPRsSvs1aPJRmKbpfUSHIUQKYBa0q/KPwW+Iykekmnkuy7/vYg1DxJ0puBm4HPRcSWw3m9tFf9VeCLko5M36NR0qvzqKVW0psljU93GewAenM0fRDYDfxd+n/gXOC1PDvfwaxkOeDNBpBOQPt74PMkAfAgyXD8eRHRmdH0B8ClwDaSfdVvSEMDkt70J9Mh5I8OYnlnkOxL/kLmbPp03afS9duBH5E1UTCPmi4HZpL0Xu8G/iEifnoYtT6S1rYGeBfJPvPrDvKcfH08fd0H0t0RP+PZfewHcwXwVPq8vyE9MiJTRHSRTCq8kGTE4D+At0bEnwahdrMh5RPdmB0GSdcDx0fEfuFgZlZM7sGbmZlVIAe8mZlZBfIQvZmZWQVyD97MzKwCOeDNzMwqkAPezMysAjngzczMKpAD3szMrAI54M3MzCrQ/wf5B+PIVt32OQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('seaborn-colorblind')\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.plot(d_list, results)#, label='', linewidth=2)\n",
    "\n",
    "# ax.set_ylim([560,740])\n",
    "ax.set_xlabel('Optimization Dimension', fontsize='large')\n",
    "ax.set_ylabel('Accuracy', fontsize='large')\n",
    "# ax.legend(loc='best', prop={'size': 10})\n",
    "# ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "plt.savefig('../output/imgs/DenseProjSmallFCNetMNIST.png', bbox='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n",
    "* Implement a slightly more general model to compute intrinsic dimension for a CNN. \n",
    "* Use a sparse matrix instead of dense for projection to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntrinsicNet(nn.Module):\n",
    "    ''' Optimize subspace of parameters of network defined as  using dense projection.\n",
    "    \n",
    "    d: intrinsic dimension size to test\n",
    "    layers: torch.nn.ModuleDict()\n",
    "    config: dict with same keys as layers, containing 3 objects: \n",
    "            'type' (str): type of layer\n",
    "            'params' (dict) : all the params to specify the layer (type, ...)\n",
    "            'activation' (dict) : if there is an activation after the layer\n",
    "    \n",
    "    ??? This still won't work for resnets, or any other more complex network\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, d, layers, config, DEVICE='cuda'):\n",
    "        super(IntrinsicNet, self).__init__()\n",
    "        self.d = d\n",
    "        self.layers = layers\n",
    "        self.config = config\n",
    "        self.opt_basis = nn.Parameter(torch.zeros(self.d).to(DEVICE), requires_grad=True)\n",
    "        self.get_projection_matrix()\n",
    "            \n",
    "    def get_projection_matrix(self):\n",
    "        self.D = 0\n",
    "        for name, layer in self.layers.items():\n",
    "            self.D += torch.prod(torch.tensor(layer.weight.size()))\n",
    "            if layer.bias is not None:\n",
    "                self.D += torch.prod(torch.tensor(layer.bias.size()))\n",
    "            layer.requires_grad = False # none of the layers will be updated\n",
    "        \n",
    "        proj_matrix = nn.Parameter(torch.randn(self.D, self.d).to(DEVICE), requires_grad=False)\n",
    "        proj_matrix = F.normalize(proj_matrix, dim=1, p=2)\n",
    "        \n",
    "        # Turn it into a nice format for a weight and bias matrix for each layer\n",
    "        param_idx = 0\n",
    "        self.projection = {}\n",
    "        for name, layer in self.layers.items():\n",
    "            self.projection[name] = {}\n",
    "            n_weight_params = torch.prod(torch.tensor(layer.weight.size()))\n",
    "            self.projection[name]['weight'] = proj_matrix[param_idx : param_idx + n_weight_params, :]\n",
    "            self.projection[name]['weight'].requires_grad = False\n",
    "            # also make sure the layers aren't trainable\n",
    "            self.layers[name].weight.requires_grad = False\n",
    "            param_idx += n_weight_params\n",
    "            if layer.bias is not None:\n",
    "                n_bias_params = torch.prod(torch.tensor(layer.bias.size()))\n",
    "                self.projection[name]['bias'] = proj_matrix[param_idx : param_idx + n_bias_params, :]\n",
    "                self.projection[name]['bias'].requires_grad = False\n",
    "                # also make sure the layers aren't trainable\n",
    "                self.layers[name].bias.requires_grad = False\n",
    "                param_idx += n_bias_params\n",
    "#         print(f'Model contains {self.D} params, but only optimizing a {self.d} dim subspace')\n",
    "\n",
    "    def get_sparse_projection_matrix(self):\n",
    "        \n",
    "        M = SRP(weight_basis.size)._make_random_matrix(weight_basis.size,total_dim)\n",
    "        fm=find(M)\n",
    "        \n",
    "        idx = torch.tensor(np.array([fm[0],fm[1]]).T)\n",
    "        vals = torch.tensor(fm[2])\n",
    "        torch.sparse.FloatTensor(i, v, (self.d, self.D)).to_dense()\n",
    "        \n",
    "        look here:\n",
    "        https://github.com/uber-research/intrinsic-dimension/blob/9754ebe1954e82973c7afe280d2c59850f281dca/keras_ext/rproj_layers_util.py\n",
    "        \n",
    "\n",
    "    def get_layer_activation(self, name):\n",
    "        mapping={'linear':F.linear,\n",
    "                 'conv2d': F.conv2d,\n",
    "                 'relu': F.relu\n",
    "                }\n",
    "        return mapping[name]\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        for name, layer in self.layers.items():\n",
    "            if self.config[name]['layer_type'] in ['linear', 'conv2d']:\n",
    "                new_weight = self.layers[name].weight + torch.matmul(self.projection[name]['weight'], self.opt_basis\n",
    "                                                           ).view(self.layers[name].weight.size())\n",
    "                new_bias = self.layers[name].bias + torch.matmul(self.projection[name]['bias'], self.opt_basis\n",
    "                                                           ).view(self.layers[name].bias.size())\n",
    "\n",
    "\n",
    "                layer = self.get_layer_activation(self.config[name]['layer_type'])\n",
    "                \n",
    "                params = self.config[name]['params']\n",
    "                \n",
    "                params['weight'] = new_weight\n",
    "                params['bias'] = new_bias\n",
    "                    \n",
    "            elif self.config[name]['layer_type'] == 'bn':\n",
    "                pass\n",
    "                \n",
    "            activation = self.get_layer_activation(self.config[name]['activation'])\n",
    "            \n",
    "            \n",
    "            x = layer(input=x, **params)\n",
    "            if activation is not None:\n",
    "                x = activation(x)\n",
    "        x = x.squeeze()                \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 15.40 GiB (GPU 1; 11.91 GiB total capacity; 4.00 KiB already allocated; 11.42 GiB free; 2.00 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b41039114f9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist_loaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIntrinsicNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'CNN Acc with 1024 params: {metrics[\"val\"][\"best_acc\"]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-6f46606839fd>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, d, layers, config, DEVICE)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt_basis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_projection_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_projection_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-6f46606839fd>\u001b[0m in \u001b[0;36mget_projection_matrix\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;31m# none of the layers will be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mproj_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mproj_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproj_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 15.40 GiB (GPU 1; 11.91 GiB total capacity; 4.00 KiB already allocated; 11.42 GiB free; 2.00 MiB cached)"
     ]
    }
   ],
   "source": [
    "layers = torch.nn.ModuleDict()\n",
    "layers['conv1'] = nn.Conv2d(1, 128, 5, stride=2, padding=2)\n",
    "layers['conv2'] = nn.Conv2d(128, 256, 5, stride=2, padding=2)\n",
    "layers['conv3'] = nn.Conv2d(256, 256, 7, stride=1, padding=0)\n",
    "layers['conv4'] = nn.Conv2d(256, 10, 1, stride=1, padding=0)\n",
    "config = {}\n",
    "config['conv1'] = {'layer_type': 'conv2d',\n",
    "                   'activation': 'relu', \n",
    "                   'params': {\n",
    "                       'stride': 2, 'padding':2\n",
    "                   } \n",
    "                  }\n",
    "config['conv2'] = {'layer_type': 'conv2d',\n",
    "                   'activation': 'relu', \n",
    "                   'params': {\n",
    "                       'stride': 2, 'padding':2\n",
    "                   }\n",
    "                   }\n",
    "                   \n",
    "config['conv3'] = {'layer_type': 'conv2d',\n",
    "                   'activation': 'relu',\n",
    "                   'params': {\n",
    "                       'stride': 1, 'padding':0\n",
    "                   }\n",
    "                   } \n",
    "config['conv4'] = {'layer_type': 'conv2d',\n",
    "                   'activation': None,\n",
    "                   'params': {\n",
    "                       'stride': 1, 'padding':0\n",
    "                   }\n",
    "                   }\n",
    "                   \n",
    "train_loader, val_loader = mnist_loaders(PATH, bs=256)\n",
    "model = IntrinsicNet(d=1024, layers=layers, config=config, DEVICE=DEVICE).to(DEVICE)\n",
    "metrics = train_net(model, train_loader, val_loader, epochs=30, verbose=0, device=DEVICE)\n",
    "print(f'CNN Acc with 1024 params: {metrics[\"val\"][\"best_acc\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare intrinsic dimension of a few CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vsmall_layers = torch.nn.ModuleDict()\n",
    "vsmall_layers['conv1'] = nn.Conv2d(1, 64, 5, stride=2, padding=2)\n",
    "vsmall_layers['conv2'] = nn.Conv2d(64, 100, 5, stride=2, padding=2)\n",
    "vsmall_layers['conv3'] = nn.Conv2d(100, 100, 7, stride=1, padding=0)\n",
    "vsmall_layers['conv4'] = nn.Conv2d(100, 10, 1, stride=1, padding=0)\n",
    "vsmall_config = {}\n",
    "vsmall_config['conv1'] = {'layer_type': 'conv2d',\n",
    "                       'activation': 'relu', \n",
    "                       'params': {\n",
    "                           'stride': 2, 'padding':2\n",
    "                       } \n",
    "                      }\n",
    "vsmall_config['conv2'] = {'layer_type': 'conv2d',\n",
    "                           'activation': 'relu', \n",
    "                           'params': {\n",
    "                               'stride': 2, 'padding':2\n",
    "                           }\n",
    "                           }\n",
    "\n",
    "vsmall_config['conv3'] = {'layer_type': 'conv2d',\n",
    "                           'activation': 'relu',\n",
    "                           'params': {\n",
    "                               'stride': 1, 'padding':0\n",
    "                           }\n",
    "                           } \n",
    "vsmall_config['conv4'] = {'layer_type': 'conv2d',\n",
    "                           'activation': None,\n",
    "                           'params': {\n",
    "                               'stride': 1, 'padding':0\n",
    "                           }\n",
    "                           }\n",
    "\n",
    "small_layers = torch.nn.ModuleDict()\n",
    "small_layers['conv1'] = nn.Conv2d(1, 128, 5, stride=2, padding=2)\n",
    "small_layers['conv2'] = nn.Conv2d(128, 256, 5, stride=2, padding=2)\n",
    "small_layers['conv3'] = nn.Conv2d(256, 256, 7, stride=1, padding=0)\n",
    "small_layers['conv4'] = nn.Conv2d(256, 10, 1, stride=1, padding=0)\n",
    "small_config = {}\n",
    "small_config['conv1'] = {'layer_type': 'conv2d',\n",
    "                       'activation': 'relu', \n",
    "                       'params': {\n",
    "                           'stride': 2, 'padding':2\n",
    "                       } \n",
    "                      }\n",
    "small_config['conv2'] = {'layer_type': 'conv2d',\n",
    "                           'activation': 'relu', \n",
    "                           'params': {\n",
    "                               'stride': 2, 'padding':2\n",
    "                           }\n",
    "                           }\n",
    "\n",
    "small_config['conv3'] = {'layer_type': 'conv2d',\n",
    "                           'activation': 'relu',\n",
    "                           'params': {\n",
    "                               'stride': 1, 'padding':0\n",
    "                           }\n",
    "                           } \n",
    "small_config['conv4'] = {'layer_type': 'conv2d',\n",
    "                           'activation': None,\n",
    "                           'params': {\n",
    "                               'stride': 1, 'padding':0\n",
    "                           }\n",
    "                           }\n",
    "\n",
    "med_layers = torch.nn.ModuleDict()\n",
    "med_layers['conv1'] = nn.Conv2d(1, 128, 5, stride=2, padding=2)\n",
    "med_layers['conv2'] = nn.Conv2d(128, 128, 5, stride=1, padding=2)\n",
    "med_layers['conv3'] = nn.Conv2d(256, 512, 5, stride=2, padding=2)\n",
    "med_layers['conv4'] = nn.Conv2d(512, 512, 7, stride=1, padding=0)\n",
    "med_layers['conv5'] = nn.Conv2d(512, 10, 1, stride=1, padding=0)\n",
    "med_config = {}\n",
    "med_config['conv1'] = {'layer_type': 'conv2d',\n",
    "                       'activation': 'relu', \n",
    "                       'params': {\n",
    "                           'stride': 2, 'padding':2\n",
    "                       } \n",
    "                      }\n",
    "med_config['conv2'] = {'layer_type': 'conv2d',\n",
    "                           'activation': 'relu', \n",
    "                           'params': {\n",
    "                               'stride': 1, 'padding':2\n",
    "                           }\n",
    "                           }\n",
    "med_config['conv3'] = {'layer_type': 'conv2d',\n",
    "                           'activation': 'relu', \n",
    "                           'params': {\n",
    "                               'stride': 2, 'padding':2\n",
    "                           }\n",
    "                           }\n",
    "med_config['conv4'] = {'layer_type': 'conv2d',\n",
    "                           'activation': 'relu',\n",
    "                           'params': {\n",
    "                               'stride': 1, 'padding':0\n",
    "                           }\n",
    "                           } \n",
    "med_config['conv5'] = {'layer_type': 'conv2d',\n",
    "                           'activation': None,\n",
    "                           'params': {\n",
    "                               'stride': 1, 'padding':0\n",
    "                           }\n",
    "                           }\n",
    "\n",
    "\n",
    "results = {}\n",
    "results['d_list'] = [8, 16, 32, 64, 128, 256, 512, 1024, 2056]\n",
    "results['vsmall'] = []\n",
    "results['small'] = []\n",
    "results['med'] = []\n",
    "\n",
    "for d in results['d_list']:\n",
    "    train_loader, val_loader = mnist_loaders(PATH, bs=256)\n",
    "    \n",
    "    model = IntrinsicNet(d=1024, layers=vsmall_layers, config=vsmall_config, DEVICE=DEVICE).to(DEVICE)\n",
    "    metrics = train_net(model, train_loader, val_loader, epochs=30, verbose=0, device=DEVICE)\n",
    "    results['vsmall'].append(metrics[\"val\"][\"best_acc\"])\n",
    "    \n",
    "    model = IntrinsicNet(d=1024, layers=small_layers, config=small_config, DEVICE=DEVICE).to(DEVICE)\n",
    "    metrics = train_net(model, train_loader, val_loader, epochs=30, verbose=0, device=DEVICE)\n",
    "    results['small'].append(metrics[\"val\"][\"best_acc\"])\n",
    "    \n",
    "    model = IntrinsicNet(d=1024, layers=med_layers, config=med_config, DEVICE=DEVICE).to(DEVICE)\n",
    "    metrics = train_net(model, train_loader, val_loader, epochs=30, verbose=0, device=DEVICE)\n",
    "    results['med'].append(metrics[\"val\"][\"best_acc\"])\n",
    "          \n",
    "plt.style.use('seaborn-colorblind')\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.plot(d_list, results['vsmall'], label='', linewidth=2)\n",
    "ax.plot(d_list, results['small'], label='', linewidth=2)\n",
    "ax.plot(d_list, results['med'], label='', linewidth=2)\n",
    "ax.set_xlabel('Optimization Subspace Dimension', fontsize='large')\n",
    "ax.set_ylabel('Accuracy', fontsize='large')\n",
    "ax.legend(loc='best', prop={'size': 10})\n",
    "plt.savefig('../output/imgs/CNN_compare_MNIST.png', bbox='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HVAE",
   "language": "python",
   "name": "hvae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
